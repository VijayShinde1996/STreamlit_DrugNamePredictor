{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a35045d",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c0025b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries -\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import string\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356da9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset -\n",
    "df_train = pd.read_csv('drugsComTrain_raw.csv', sep=\",\", encoding=\"utf-8\")\n",
    "df_test = pd.read_csv('drugsComTest_raw.csv', sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7085575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype of date from object to DateTime -\n",
    "df_train['date'] = pd.to_datetime(df_train['date'], format='%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Top 5 Rows -\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c027f",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null Values -\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Null Values -\n",
    "sns.heatmap(df_train.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null records -\n",
    "df_train = df_train.dropna()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b7471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "df_train[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "df_train[\"drugName\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cbc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Unwanted features -\n",
    "df_train = df_train.drop(\"uniqueID\", axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-variate Analysis\n",
    "\n",
    "# 1. Distribution of ratings\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='rating', data=df_train, palette='coolwarm')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. Most common conditions\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_train['condition'].value_counts().head(10).plot(kind='barh', color='skyblue')\n",
    "plt.title('Top 5 Most Common Conditions')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Condition')\n",
    "plt.show()\n",
    "\n",
    "# 3. Most reviewed drugs\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_train['drugName'].value_counts().head(5).plot(kind='barh', color='lightgreen')\n",
    "plt.title('Top 5 Most Reviewed Drugs')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Drug Name')\n",
    "plt.show()\n",
    "\n",
    "# 4. Helpful reviews - usefulCount distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_train['usefulCount'], bins=10, color='purple')\n",
    "plt.title('Distribution of Useful Counts in Reviews')\n",
    "plt.xlabel('Useful Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uni-variate Analysis\n",
    "# 1. Univariate analysis of 'rating'\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_train['rating'], bins=10, kde=True, color='orange')\n",
    "plt.title('Univariate Analysis: Rating Distribution')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# 2. Univariate analysis of 'condition' frequency\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_train['condition'].value_counts().head(10).plot(kind='bar', color='lightblue')\n",
    "plt.title('Univariate Analysis: Top 10 Conditions by Frequency')\n",
    "plt.xlabel('Condition')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 3. Univariate analysis of 'usefulCount' distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=df_train['usefulCount'], color='green')\n",
    "plt.title('Univariate Analysis: Distribution of Useful Counts')\n",
    "plt.xlabel('Useful Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2145724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis - Descriptive Statistics\n",
    "\n",
    "# 1. Descriptive statistics for numerical columns\n",
    "print(\"Descriptive Statistics for Numerical Columns:\")\n",
    "print(df_train[['rating', 'usefulCount']].describe())\n",
    "\n",
    "# 2. Frequency count for categorical variables\n",
    "print(\"\\nFrequency Count for Conditions:\")\n",
    "print(df_train['condition'].value_counts())\n",
    "\n",
    "print(\"\\nFrequency Count for Drug Names:\")\n",
    "print(df_train['drugName'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c34d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Analysis - Correlation and Grouped Statistics\n",
    "\n",
    "# 1. Correlation between numerical variables\n",
    "print(\"\\nCorrelation between Rating and Useful Count:\")\n",
    "print(df_train[['rating', 'usefulCount']].corr())\n",
    "\n",
    "# 2. Groupby statistics for categorical and numerical relationships\n",
    "\n",
    "# Average rating for each condition\n",
    "print(\"\\nAverage Rating for Each Condition:\")\n",
    "print(df_train.groupby('condition')['rating'].mean())\n",
    "\n",
    "# Average useful count for each drug\n",
    "print(\"\\nAverage Useful Count for Each Drug:\")\n",
    "print(df_train.groupby('drugName')['usefulCount'].mean())\n",
    "\n",
    "# Rating variance for each condition\n",
    "print(\"\\nRating Variance for Each Condition:\")\n",
    "print(df_train.groupby('condition')['rating'].var())\n",
    "\n",
    "# Useful count median for each drug\n",
    "print(\"\\nMedian Useful Count for Each Drug:\")\n",
    "print(df_train.groupby('drugName')['usefulCount'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37776fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of dataset -\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83e717",
   "metadata": {},
   "source": [
    "# World Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22de9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset -\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f116a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need only condition and review \n",
    "X = df_train.drop(['drugName','rating','date','usefulCount'],axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f9b41",
   "metadata": {},
   "source": [
    "# Text Preprocessing // Data Cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783609e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleanning -\n",
    "# Function to clean and preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML characters like &#039; and other special characters\n",
    "    text = re.sub(r'&#\\d+;', '', text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "# Clean all the reviews in the 'review' column\n",
    "df_train['cleaned_review'] = df_train['review'].apply(preprocess_text)\n",
    "\n",
    "# Combine all the reviews into a single text\n",
    "all_reviews = ' '.join(df_train['cleaned_review'])\n",
    "all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf27f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the WordCloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=all_reviews,\n",
    "    colormap='coolwarm',  # Change colormap to your preference\n",
    "    max_words=500,        # Limit the number of words in the cloud\n",
    "    contour_color='black',  # Contour color around words\n",
    "    contour_width=3\n",
    ").generate(all_reviews)\n",
    "\n",
    "# Display the Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Medication Reviews', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all the reviews in the 'review' column\n",
    "df_train['cleaned_drugName'] = df_train['drugName'].apply(preprocess_text)\n",
    "\n",
    "# Combine all the reviews into a single text\n",
    "all_drugName = ' '.join(df_train['cleaned_drugName'])\n",
    "all_drugName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the WordCloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=all_reviews,\n",
    "    colormap='coolwarm',  # Change colormap to your preference\n",
    "    max_words=500,        # Limit the number of words in the cloud\n",
    "    contour_color='black',  # Contour color around words\n",
    "    contour_width=3\n",
    ").generate(all_drugName)\n",
    "\n",
    "# Display the Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Drug Name', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b16762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all the reviews in the 'review' column\n",
    "df_train['cleaned_condition'] = df_train['condition'].apply(preprocess_text)\n",
    "\n",
    "# Combine all the reviews into a single text\n",
    "all_condition= ' '.join(df_train['cleaned_condition'])\n",
    "all_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e54f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the WordCloud\n",
    "wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    stopwords=all_reviews,\n",
    "    colormap='coolwarm',  # Change colormap to your preference\n",
    "    max_words=500,        # Limit the number of words in the cloud\n",
    "    contour_color='black',  # Contour color around words\n",
    "    contour_width=3\n",
    ").generate(all_condition)\n",
    "\n",
    "# Display the Word Cloud\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Patient Condition', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3111ef",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482af53",
   "metadata": {},
   "source": [
    "## Model to Predict Patient Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cccd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "print(df_train['condition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b2ebf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts for 'condition'\n",
    "value_counts = df_train['condition'].value_counts()\n",
    "\n",
    "# Filter the 'condition' column to keep only values with counts >= 40\n",
    "valid_conditions = value_counts[value_counts >= 500].index\n",
    "\n",
    "# Filter the DataFrame based on valid conditions\n",
    "df_train = df_train[df_train['condition'].isin(valid_conditions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "print(df_train['condition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d323328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(reviews):\n",
    "    # Define a function to clean a single review\n",
    "    def clean_review(review):\n",
    "        # Convert HTML entities\n",
    "        review = review.replace('&#039;', \"'\").replace('&amp;', '&')\n",
    "        # Remove special characters using regex\n",
    "        return re.sub(r'[^\\w\\s]', '', review)\n",
    "\n",
    "    # Apply the cleaning function to the entire series\n",
    "    return reviews.apply(clean_review)\n",
    "\n",
    "# Example usage\n",
    "df_train['clean_review'] = clean_reviews(df_train['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df_train['clean_review'])\n",
    "y = df_train['condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c26568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Recall':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')  # Using 'macro' for multi-class recall\n",
    "    \n",
    "    # Print model name, accuracy, and recall\n",
    "    print(f\"{name:<20} {accuracy:<10.4f} {recall:<10.4f}\")\n",
    "    \n",
    "    # Save the best model based on accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38398951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and vectorizer using joblib\n",
    "joblib.dump(best_model, 'best_patient_condition_model.pkl')\n",
    "joblib.dump(vectorizer, 'best_patient_condition_vectorizer.pkl')\n",
    "\n",
    "print(f\"Best model with {best_accuracy} accuracy has been saved using joblib.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d81b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and vectorizer\n",
    "model = joblib.load('best_patient_condition_model.pkl')\n",
    "vectorizer = joblib.load('best_patient_condition_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbbb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean a single review\n",
    "def clean_review(review):\n",
    "    # Convert HTML entities\n",
    "    review = review.replace('&#039;', \"'\").replace('&amp;', '&')\n",
    "    # Remove special characters using regex\n",
    "    return re.sub(r'[^\\w\\s]', '', review)\n",
    "\n",
    "# Function to load and predict using the best model\n",
    "def predict_condition(new_review):\n",
    "    # Clean the new review\n",
    "    new_review_cleaned = clean_review(new_review)\n",
    "    \n",
    "    # Vectorize the cleaned review\n",
    "    new_review_vectorized = vectorizer.transform([new_review_cleaned])\n",
    "    \n",
    "    # Predict the condition\n",
    "    prediction = model.predict(new_review_vectorized)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction function\n",
    "new_text = \"I have severe depression and can't seem to find a medication that helps me.\"\n",
    "predicted_condition = predict_condition(new_text)\n",
    "print(f\"Predicted condition: {predicted_condition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bb6f8",
   "metadata": {},
   "source": [
    "## Model to Predict Drug Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset -\n",
    "df_train = pd.read_csv('drugsComTrain_raw.csv', sep=\",\", encoding=\"utf-8\")\n",
    "df_test = pd.read_csv('drugsComTest_raw.csv', sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3235d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Null records -\n",
    "df_train = df_train.dropna()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "print(df_train['drugName'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839d104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts for 'condition'\n",
    "value_counts = df_train['drugName'].value_counts()\n",
    "\n",
    "# Filter the 'condition' column to keep only values with counts >= 40\n",
    "valid_conditions = value_counts[value_counts >= 500].index\n",
    "\n",
    "# Filter the DataFrame based on valid conditions\n",
    "df_train = df_train[df_train['drugName'].isin(valid_conditions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5633ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_Counts -\n",
    "print(df_train['drugName'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(reviews):\n",
    "    # Define a function to clean a single review\n",
    "    def clean_review(review):\n",
    "        # Convert HTML entities\n",
    "        review = review.replace('&#039;', \"'\").replace('&amp;', '&')\n",
    "        # Remove special characters using regex\n",
    "        return re.sub(r'[^\\w\\s]', '', review)\n",
    "\n",
    "    # Apply the cleaning function to the entire series\n",
    "    return reviews.apply(clean_review)\n",
    "\n",
    "# Example usage\n",
    "df_train['clean_review'] = clean_reviews(df_train['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df_train['clean_review'])\n",
    "y = df_train['drugName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90046c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "print(f\"{'Model':<20} {'Accuracy':<10} {'Recall':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')  # Using 'macro' for multi-class recall\n",
    "    \n",
    "    # Print model name, accuracy, and recall\n",
    "    print(f\"{name:<20} {accuracy:<10.4f} {recall:<10.4f}\")\n",
    "    \n",
    "    # Save the best model based on accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ec304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and vectorizer using joblib\n",
    "joblib.dump(best_model, 'best_drug_name_model.pkl')\n",
    "joblib.dump(vectorizer, 'best_drug_name_vectorizer.pkl')\n",
    "\n",
    "print(f\"Best model with {best_accuracy} accuracy has been saved using joblib.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721efadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and vectorizer\n",
    "model = joblib.load('best_drug_name_model.pkl')\n",
    "vectorizer = joblib.load('best_drug_name_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean a single review\n",
    "def clean_review(review):\n",
    "    # Convert HTML entities\n",
    "    review = review.replace('&#039;', \"'\").replace('&amp;', '&')\n",
    "    # Remove special characters using regex\n",
    "    return re.sub(r'[^\\w\\s]', '', review)\n",
    "\n",
    "# Function to load and predict using the best model\n",
    "def predict_condition(new_review):\n",
    "    # Clean the new review\n",
    "    new_review_cleaned = clean_review(new_review)\n",
    "    \n",
    "    # Vectorize the cleaned review\n",
    "    new_review_vectorized = vectorizer.transform([new_review_cleaned])\n",
    "    \n",
    "    # Predict the condition\n",
    "    prediction = model.predict(new_review_vectorized)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the prediction function\n",
    "new_text = \"I have severe depression and can't seem to find a medication that helps me.\"\n",
    "predicted_condition = predict_condition(new_text)\n",
    "print(f\"Predicted Drug Name: {predicted_condition}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf5fbb6",
   "metadata": {},
   "source": [
    "# Thank You VRS Foundation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vrsGlobal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
